{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert-finetune.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNb2TCM/7dLVuUvTv74mvY0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"5TrYkWIiSTOK"},"source":["# Finetuning of german-sentiment-bert\n","\n","To be executed in Google Colab"]},{"cell_type":"markdown","metadata":{"id":"cQYOkvFTvPkz"},"source":["## Set up Colab"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UvoND0i3q_Bq","executionInfo":{"status":"ok","timestamp":1614143578096,"user_tz":-60,"elapsed":1757,"user":{"displayName":"Martin D.","photoUrl":"","userId":"10568500020328497771"}},"outputId":"01e0e228-2a2d-45f5-8f8c-65dfe3cd7714"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","basepath = '/content/drive/My Drive/text-analytics/news-sentiment/training'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UH1Z9g1qJk-0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614143581958,"user_tz":-60,"elapsed":3012,"user":{"displayName":"Martin D.","photoUrl":"","userId":"10568500020328497771"}},"outputId":"566fee18-6e9c-4c0a-905d-c31bdc82969b"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U0XI7YjFJcf2","executionInfo":{"status":"ok","timestamp":1614143585188,"user_tz":-60,"elapsed":5507,"user":{"displayName":"Martin D.","photoUrl":"","userId":"10568500020328497771"}}},"source":["import csv\n","import os\n","import re\n","from typing import Dict, Optional\n","\n","import torch\n","import torch.nn.functional as F\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SjAHUoeMvKTn"},"source":["## Define dataset class\n","\n","For sentiment analysis data stored in CSV"]},{"cell_type":"code","metadata":{"id":"B_IK0aEPJuG4","executionInfo":{"status":"ok","timestamp":1614143585190,"user_tz":-60,"elapsed":4641,"user":{"displayName":"Martin D.","photoUrl":"","userId":"10568500020328497771"}}},"source":["label_names = {0: 'positive', 1: 'negative', 2: 'neutral'}\n","\n","\n","class SentiCSVDataset(torch.utils.data.Dataset):\n","    \"\"\"Custom dataset class for sentiment analysis data in a CSV file.\n","    \n","    Tailored towards the pretrained model oliverguhr/german-sentiment-bert.\n","\n","    The methods replace_numbers() and clean_text() are based on\n","    https://github.com/oliverguhr/german-sentiment-lib/blob/4e5158/germansentiment/sentimentmodel.py\"\"\"\n","    def __init__(\n","            self,\n","            csv_path: str,\n","            csv_delimiter: str = '\\t',\n","            label_remap: Optional[Dict[int, int]] = None\n","    ):\n","        self.csv_path = csv_path\n","\n","        self.clean_chars = re.compile(r'[^A-Za-züöäÖÜÄß ]', re.MULTILINE)\n","        self.clean_http_urls = re.compile(r'https*\\S+', re.MULTILINE)\n","        self.clean_at_mentions = re.compile(r'@\\S+', re.MULTILINE)\n","\n","        if label_remap is None:\n","            label_remap = {}\n","\n","        raw_texts = []\n","        raw_labels = []\n","        # Load all data during initialization so iteration is faster.\n","        # This works fine as long as the dataset is extremely large.\n","        if csv_path is not None:\n","            with open(os.path.expanduser(csv_path), 'r') as f:\n","                reader = csv.reader(f, delimiter=csv_delimiter)\n","                for row in reader:\n","                    if len(row) != 2:\n","                        raise ValueError('Invalid row encountered.')\n","                    text = self.clean_text(row[0])\n","                    label = int(row[1])\n","                    # If the label has an entry in the label_remap dict,\n","                    # it is remapped accordingly. Else, the label is kept.\n","                    label = label_remap.get(label, label)\n","                    raw_texts.append(text)\n","                    raw_labels.append(label)\n","        else:  # Default data for testing\n","            raw_texts = [\n","                'Du hirnloser Vollidiot!', 'Ich mag dich sehr.', 'Alles hat ein Ende.', 'Nur die Wurst hat zwei.',\n","                'So ist das Leben.', 'Der zu frühe Vogel muss auf den Wurm warten.', 'Was für eine Katastrophe.'\n","            ]\n","            raw_labels = [1, 0, 2, 2, 2, 2, 1]\n","       \n","        self.raw_texts = raw_texts\n","        self.raw_labels = raw_labels\n","\n","        self.tokenizer = AutoTokenizer.from_pretrained('oliverguhr/german-sentiment-bert')\n","        self.encodings = self.tokenizer(self.raw_texts, return_tensors='pt', truncation=True, padding=True)\n","        self.input_ids = self.encodings['input_ids']\n","\n","        self.labels = torch.tensor(self.raw_labels, dtype=torch.int64)\n","\n","    def replace_numbers(self, text: str) -> str:\n","        return text.replace(\"0\",\" null\").replace(\"1\",\" eins\").replace(\"2\",\" zwei\")\\\n","            .replace(\"3\",\" drei\").replace(\"4\",\" vier\").replace(\"5\",\" fünf\") \\\n","            .replace(\"6\",\" sechs\").replace(\"7\",\" sieben\").replace(\"8\",\" acht\") \\\n","            .replace(\"9\",\" neun\")         \n","\n","    def clean_text(self, text: str) -> str:    \n","        text = text.replace(\"\\n\", \" \")        \n","        text = self.clean_http_urls.sub('', text)\n","        text = self.clean_at_mentions.sub('', text)        \n","        text = self.replace_numbers(text)                \n","        text = self.clean_chars.sub('', text) # use only text chars                          \n","        text = ' '.join(text.split()) # substitute multiple whitespace with single whitespace   \n","        text = text.strip().lower()\n","        return text\n","\n","    def __getitem__(self, idx):\n","        item = {\n","            'input_ids': self.input_ids[idx],\n","            'labels': self.labels[idx]\n","        }\n","        return item\n","\n","    def __len__(self):\n","        return len(self.raw_labels)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tg6EQE4Lvmcs"},"source":["## Load datasets and model"]},{"cell_type":"code","metadata":{"id":"tpTg29rrJwK5","executionInfo":{"status":"ok","timestamp":1614143590458,"user_tz":-60,"elapsed":8520,"user":{"displayName":"Martin D.","photoUrl":"","userId":"10568500020328497771"}}},"source":["# Remap \"hostile\" label (3) to \"negative\" (1) because the model does not yet support 4 classes\n","label_remap = {3: 1}\n","\n","train_dataset = SentiCSVDataset(f'{basepath}/train.csv', label_remap=label_remap)\n","\n","eval_dataset = SentiCSVDataset(f'{basepath}/validation.csv', label_remap=label_remap)\n","\n","model = AutoModelForSequenceClassification.from_pretrained('oliverguhr/german-sentiment-bert')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k-wGDW-3034b","executionInfo":{"status":"ok","timestamp":1614143590460,"user_tz":-60,"elapsed":6672,"user":{"displayName":"Martin D.","photoUrl":"","userId":"10568500020328497771"}},"outputId":"0f0937f4-bbb2-4fc1-faab-7c3be3eac6a8"},"source":["from collections import Counter\n","\n","train_label_counts = Counter(train_dataset.raw_labels)\n","print('Label counts in training set:')\n","for i in range(3):\n","    ci = train_label_counts[i]\n","    pct = 100 * ci / len(train_dataset.raw_labels)\n","    print(f'{label_names[i]} ({i}):\\t{ci} samples ({pct:.1f}%)')\n","print('\\nLabel counts in validation set:')\n","validation_label_counts = Counter(eval_dataset.raw_labels)\n","for i in range(3):\n","    ci = validation_label_counts[i]\n","    pct = 100 * ci / len(eval_dataset.raw_labels)\n","    print(f'{label_names[i]} ({i}):\\t{ci} samples ({pct:.1f}%)')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Label counts in training set:\n","positive (0):\t267 samples (18.0%)\n","negative (1):\t615 samples (41.4%)\n","neutral (2):\t603 samples (40.6%)\n","\n","Label counts in validation set:\n","positive (0):\t27 samples (16.4%)\n","negative (1):\t65 samples (39.4%)\n","neutral (2):\t73 samples (44.2%)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HtPv2Tpavv42"},"source":["## Set up training\n","\n","And evaluate performance before training"]},{"cell_type":"code","metadata":{"id":"15BIHiC9J0D7","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1614143599354,"user_tz":-60,"elapsed":5222,"user":{"displayName":"Martin D.","photoUrl":"","userId":"10568500020328497771"}},"outputId":"01223fa3-bbe5-453d-fcc0-2fedf48a6f31"},"source":["output_dir = f'{basepath}/results'\n","logging_dir = f'{basepath}/logs'\n","\n","training_args = TrainingArguments(\n","    output_dir=output_dir,\n","    learning_rate=8e-6,\n","    num_train_epochs=7,\n","    per_device_train_batch_size=20,\n","    per_device_eval_batch_size=32,\n","    warmup_steps=120,\n","    weight_decay=0.01,\n","    logging_dir=logging_dir,\n","    load_best_model_at_end=True,\n","    evaluation_strategy='epoch',\n","    dataloader_num_workers=1,\n","    logging_first_step=True,\n","    logging_steps=47,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset\n",")\n","\n","# Show how it performs before training\n","trainer.evaluate()"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6/6 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 5.430793762207031,\n"," 'eval_runtime': 1.9356,\n"," 'eval_samples_per_second': 85.246}"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"q2mlaYoXv9Qm"},"source":["## Show tensorboard dashboard\n","\n","Optional. Note that this results in huge cell outputs which can cause problems with saving the notebook. If saving no longer works or is slow, clear the output of the following cell."]},{"cell_type":"code","metadata":{"id":"snIi61cBKLyv"},"source":["%load_ext tensorboard\n","%tensorboard --logdir '/content/drive/My Drive/text-analytics/news-sentiment/training/logs'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t9vgUlgev6fX"},"source":["## Train and evaluate"]},{"cell_type":"code","metadata":{"id":"kwDJ0q8pJ3s6","colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"status":"ok","timestamp":1614144074684,"user_tz":-60,"elapsed":475000,"user":{"displayName":"Martin D.","photoUrl":"","userId":"10568500020328497771"}},"outputId":"af77c10a-bdcc-4a73-95b3-0225c7d47c2b"},"source":["trainer.train()\n","\n","# Show how it performs after training\n","trainer.evaluate()"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='525' max='525' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [525/525 07:51, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Runtime</th>\n","      <th>Samples Per Second</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>4.088000</td>\n","      <td>1.229975</td>\n","      <td>1.603900</td>\n","      <td>102.875000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.974700</td>\n","      <td>1.061316</td>\n","      <td>1.600800</td>\n","      <td>103.076000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.937100</td>\n","      <td>0.995773</td>\n","      <td>1.611900</td>\n","      <td>102.363000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.799000</td>\n","      <td>1.017731</td>\n","      <td>1.608000</td>\n","      <td>102.611000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.763100</td>\n","      <td>1.077186</td>\n","      <td>1.601000</td>\n","      <td>103.060000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.670400</td>\n","      <td>1.110236</td>\n","      <td>1.609800</td>\n","      <td>102.496000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.645400</td>\n","      <td>1.116556</td>\n","      <td>1.608000</td>\n","      <td>102.611000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='12' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6/6 01:07]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6/6 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 7.0,\n"," 'eval_loss': 1.1165564060211182,\n"," 'eval_runtime': 1.6133,\n"," 'eval_samples_per_second': 102.276}"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"QLLyekTQdLPc"},"source":[""],"execution_count":null,"outputs":[]}]}